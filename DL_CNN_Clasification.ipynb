{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_CNN_Clasification.ipynb","provenance":[],"authorship_tag":"ABX9TyPxfanxw1UVutC2rZPpUviT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TDGRo9Ch8CtE"},"source":["\n","Classification with CIFAR-10 Dataset\n"]},{"cell_type":"code","metadata":{"id":"fxPL4QPEogCQ"},"source":["from tensorflow import keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pF9m4KPUoqCZ"},"source":["#import data\n","(train_images,train_labels),(test_images,test_labels) = keras.datasets.cifar10.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6DVrsbfoqlF"},"source":["#scaling\n","train_images, test_images = train_images / 255, test_images / 255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pYIvKEC4ot_G"},"source":["from keras import layers, models, losses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"73liOHb6ouEX"},"source":["#Create model\n","model = models.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4r6rT7Jso2Pg"},"source":["#Create CNN Layers\n","model.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(32,32,3)))\n","model.add(layers.MaxPooling2D())\n","model.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n","model.add(layers.MaxPooling2D())\n","model.add(layers.Conv2D(64,(3,3),activation=\"relu\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LFteLQhHo2rn"},"source":["#Create Dense Layers\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64,activation=\"relu\"))\n","model.add(layers.Dense(10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GcKC3DiGo4CR"},"source":["#Compile Model\n","model.compile(optimizer=\"adam\",\n","              loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9zqCQBY6bLP","executionInfo":{"status":"ok","timestamp":1631129841197,"user_tz":-180,"elapsed":225,"user":{"displayName":"Hasan Aydemir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglQ2ywb--h9YfUr9_MCT_y9gx9QKCud58_ZULSuw=s64","userId":"09008824355061673945"}},"outputId":"c237e91c-a3ea-4a4a-c61e-9fe85d48bca4"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 30, 30, 32)        896       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n","_________________________________________________________________\n","flatten (Flatten)            (None, 1024)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                65600     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 122,570\n","Trainable params: 122,570\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"2lGzYX8Zo7Vq"},"source":["from keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucccYtMvo92e"},"source":["# To increase our input data we use Image Augmentation\n","datagen = ImageDataGenerator(rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BHwuXbYZpE2s"},"source":["# Fit the train_images to datagen\n","datagen.fit(train_images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"upyp9f-8pFWL","colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"status":"error","timestamp":1631130030516,"user_tz":-180,"elapsed":182944,"user":{"displayName":"Hasan Aydemir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglQ2ywb--h9YfUr9_MCT_y9gx9QKCud58_ZULSuw=s64","userId":"09008824355061673945"}},"outputId":"2b309cae-4ac1-4bc1-8f48-8d3c387f28e4"},"source":["#Fit the model with datagen\n","model.fit(datagen.flow(train_images, train_labels), \n","          batch_size= 32, steps_per_epoch=len(train_images)/32,\n","          epochs=25, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","1562/1562 [==============================] - 27s 17ms/step - loss: 1.8233 - accuracy: 0.0994\n","Epoch 2/25\n","1562/1562 [==============================] - 26s 17ms/step - loss: 1.5909 - accuracy: 0.0943\n","Epoch 3/25\n","1562/1562 [==============================] - 27s 17ms/step - loss: 1.4906 - accuracy: 0.0939\n","Epoch 4/25\n","1562/1562 [==============================] - 27s 17ms/step - loss: 1.4282 - accuracy: 0.0976\n","Epoch 5/25\n","1562/1562 [==============================] - 27s 17ms/step - loss: 1.3828 - accuracy: 0.0993\n","Epoch 6/25\n","1562/1562 [==============================] - 26s 17ms/step - loss: 1.3438 - accuracy: 0.0983\n","Epoch 7/25\n","1307/1562 [========================>.....] - ETA: 4s - loss: 1.3127 - accuracy: 0.0998"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-5c56a1133e3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(datagen.flow(train_images, train_labels), \n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           epochs=25, verbose=1)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"lTSyL0HdpHCu"},"source":["#evaluate the model and get loss with accuracy metric\n","loss = model.evaluate(datagen.flow(test_images, test_labels),batch_size=32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9xM_suK8pIy7"},"source":["prediction = model.predict(test_images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNwgALlwpKna"},"source":["import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PCB86fGlpMDT"},"source":["class_names=[\"airplane\",\"automobile\",\"bird\",\"cat\",\n","             \"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8tWIM_-pOAz"},"source":["INDEX=\"\"\n","while INDEX.isdigit() == False:\n","  INDEX = input(\"Lütfen tahmin gerçekleştirmek istediğiniz indeksi girin: \")\n","  if int(INDEX)>=len(test_images):\n","    INDEX=\"\"\n","INDEX = int(INDEX)\n","predicted_value=class_names[np.argmax(prediction[INDEX])]\n","actual_value= class_names[test_labels[INDEX][0]]\n","print(f\"Real Value: {actual_value} - Predicted Value: {predicted_value}\")\n","plt.figure()\n","plt.imshow(test_images[INDEX])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5WX4SsTMpV7M"},"source":[""],"execution_count":null,"outputs":[]}]}